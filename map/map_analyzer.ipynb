{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modules\n",
    "import numpy as np\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "map_file = 'map_cache.npy' # numpy load first, see if we have some data before\n",
    "load = True\n",
    "try:\n",
    "    map_cache = np.load(map_file)\n",
    "except:\n",
    "    load = False\n",
    "    \n",
    "apt_file = 'apt_file.npy'\n",
    "try:\n",
    "    apt_list = np.load(apt_file) # update this to be compatible, load exported data from apt.py and filter here\n",
    "except:\n",
    "    apt_list = [\n",
    "        'Royal York',\n",
    "        'Oakland Apartments',\n",
    "        'Oak Hill Apartments',\n",
    "        'The Bridge on Forbes',\n",
    "        'Schenley Apartments',\n",
    "        'One on Centre',\n",
    "        'Portal Place',\n",
    "        'Devon Towers',\n",
    "        'Amberson Gardens',\n",
    "        'Webster Hall',\n",
    "        'Fairfax Apartments',\n",
    "        'Ambassador Apartments',\n",
    "        'North Windsor Apartments',\n",
    "        'Shadyside Commons',\n",
    "    ]\n",
    "    addr_list = [\n",
    "        '3955 Bigelow Blvd, Pittsburgh, PA 15213',\n",
    "        '4629 Bayard St, Pittsburgh, PA 15213',\n",
    "        '475 Garner Ct, Pittsburgh, PA 15213',\n",
    "        '3423 Forbes Ave, Pittsburgh, PA 15213',\n",
    "        '4101 Bigelow Blvd, Pittsburgh, PA 15213',\n",
    "        '4500 Centre Ave, Pittsburgh, PA 15213',\n",
    "        '2633 Fifth Ave, Pittsburgh, PA 15213',\n",
    "        '4920 CENTRE Ave, Pittsburgh, PA 15213',\n",
    "        '1-4 Bayard Rd, Pittsburgh, PA 15213',\n",
    "        '101 N Dithridge St, Pittsburgh, PA 15213',\n",
    "        '4614 5th Ave, Pittsburgh, PA 15213',\n",
    "        '4733 Centre Ave, Pittsburgh, PA 15213',\n",
    "        '234 Melwood Ave, Pittsburgh, PA 15213',\n",
    "        '401 Amberson Ave, Pittsburgh, PA 15232',\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map Helper\n",
    "def shortest_distance_time(arg):\n",
    "    text = str(arg) # arg = bsyc\n",
    "    end_idx = 0\n",
    "    shortest_distance = 0\n",
    "    shortest_time = 0\n",
    "    while end_idx != -1:\n",
    "        # Get distance\n",
    "        end_idx = text.find(' mile', end_idx+1)\n",
    "        if end_idx == -1:\n",
    "            break\n",
    "        start_idx = end_idx\n",
    "        while(text[start_idx-1] != '['):\n",
    "            start_idx -= 1\n",
    "        end_idx = text.find(',', start_idx)\n",
    "        distance = int(text[start_idx : end_idx])\n",
    "        if shortest_distance != 0 and distance > shortest_distance: # Only do shortest distance\n",
    "            end_idx = text.find(']', end_idx) # move cursor after 'mile'\n",
    "            continue\n",
    "        shortest_distance = distance\n",
    "        # Get time for shortest distance\n",
    "        start_idx = text.find('[', end_idx) + 1\n",
    "        end_idx = text.find(',', start_idx)\n",
    "        shortest_time = int(text[start_idx : end_idx]) # small bug, we are using new time not shortest_time if same shortest_distance\n",
    "    return [shortest_distance, shortest_time]\n",
    "\n",
    "# Helper function to create query, open url, call parse api and output one data\n",
    "# Sample data: ['APT_NAM', 'DIS_DRI', 'TIM_DRI', ' DIS_WAL', 'TIM_WAL', 'DIS_BIC', 'TIM_BIC']\n",
    "travel_mode = ['driving', 'walking', 'bicycling'] #, 'transit'] # do not support transit now, noise in sub-routes\n",
    "def goog_map(apt_name, apt_addr):\n",
    "    goog_map_data = [apt_name]\n",
    "    for tm in travel_mode:\n",
    "        link = 'https://www.google.com/maps/dir/?api=1&origin=' + \\\n",
    "               (apt_name+' '+apt_addr).replace(' ', '+') + \\\n",
    "               '&destination=CMU&travelmode=' + tm\n",
    "        html = urlopen(link)\n",
    "        bsyc = BeautifulSoup(html.read(), \"lxml\")\n",
    "        time.sleep(5)\n",
    "        fout = open(apt_name+' '+tm+'.txt', 'wt',encoding='utf-8')\n",
    "        fout.write(str(bsyc))\n",
    "        fout.close()\n",
    "        goog_map_data += shortest_distance_time(bsyc)\n",
    "    return goog_map_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search\n",
    "if load:\n",
    "    apt_cache = map_cache[:,0].tolist() #[map_cache[r][0] for r in range(len(map_cache))]\n",
    "else:\n",
    "    apt_cache = [] # also needed to avoid duplicates\n",
    "apt_data_list = [] # to store new apt_data\n",
    "for apt,addr in zip(apt_list, addr_list):\n",
    "    # Data in cache, skip search\n",
    "    if apt in apt_cache:\n",
    "        continue\n",
    "    try:\n",
    "        # Read one data\n",
    "        apt_data = goog_map(apt, addr)\n",
    "        # Add data\n",
    "        apt_data_list.append(apt_data)\n",
    "        # Avoid duplicate\n",
    "        apt_cache.append(apt)\n",
    "    except:\n",
    "        print('Unable to read more map. Save current data.')\n",
    "        break\n",
    "\n",
    "# Add new data to cache\n",
    "if apt_data_list:\n",
    "    if load:\n",
    "        map_cache = np.concatenate((map_cache, np.array(apt_data_list)), axis = 0)\n",
    "    else:\n",
    "        map_cache = np.array(apt_data_list)\n",
    "# else: do nothing to map_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Royal York' '1385' '366' '1364' '1006' '1385' '371']\n",
      " ['Oakland Apartments' '943' '267' '943' '736' '943' '263']\n",
      " ['Oak Hill Apartments' '2869' '635' '2432' '1870' '3105' '678']\n",
      " ['The Bridge on Forbes' '1415' '278' '1415' '1090' '1415' '321']\n",
      " ['Schenley Apartments' '1408' '327' '1367' '997' '1438' '345']\n",
      " ['One on Centre' '1186' '319' '1186' '899' '1186' '290']\n",
      " ['Portal Place' '3627' '551' '1991' '1524' '1991' '606']\n",
      " ['Devon Towers' '1560' '299' '1410' '1058' '1483' '363']\n",
      " ['Amberson Gardens' '1464' '357' '1255' '950' '1387' '363']\n",
      " ['Webster Hall' '1200' '321' '634' '475' '631' '202']\n",
      " ['Fairfax Apartments' '551' '154' '481' '376' '551' '165']\n",
      " ['Ambassador Apartments' '1364' '304' '1342' '1037' '1302' '399']\n",
      " ['North Windsor Apartments' '1338' '392' '1027' '793' '1338' '390']\n",
      " ['Shadyside Commons' '1468' '321' '1374' '1066' '1391' '388']]\n"
     ]
    }
   ],
   "source": [
    "# Check current cache, old + new data\n",
    "print(map_cache)\n",
    "# Save all data\n",
    "np.save(map_file, map_cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
